import pandas as pd
import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager

def parse_scholar_profile(profile_url):
    if not profile_url:
        return {}

    # ì…€ë ˆë‹ˆì›€ í¬ë¡¬ ì˜µì…˜ ì„¤ì •
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')  # ë¸Œë¼ìš°ì € ì°½ ì•ˆ ë„ì›€
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--lang=en')

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.get(profile_url)
    time.sleep(2)

    soup = BeautifulSoup(driver.page_source, "html.parser")

    # ì´ë¯¸ì§€ URL
    img_tag = soup.select_one("#gsc_prf_pup-img")
    image_url = img_tag["src"] if img_tag and img_tag.has_attr("src") else None

    # ì—°êµ¬ í‚¤ì›Œë“œ
    keywords = [tag.text for tag in soup.select("#gsc_prf_int a")]

    # ì†Œì†
    aff_tag = soup.select_one("#gsc_prf_i .gsc_prf_il")
    affiliation = aff_tag.text.strip() if aff_tag else None

    # ìƒìœ„ ë…¼ë¬¸ 3ê°œ
    papers = []
    for row in soup.select("tr.gsc_a_tr")[:3]:
        title_tag = row.select_one("a.gsc_a_at")
        if title_tag:
            title = title_tag.text
            link = "https://scholar.google.com" + title_tag["href"]
            papers.append(f"{title} ({link})")

    driver.quit()

    return {
        "image_url": image_url,
        "affiliation_from_scholar": affiliation,
        "keywords": "; ".join(keywords),
        "top_papers": "; ".join(papers)
    }

# ğŸ”½ CSV íŒŒì¼ ì½ê¸°
df = pd.read_csv("./top_400_with_scholarurl.csv")  

# ğŸ”„ scholar profile_url ê¸°ë°˜ í¬ë¡¤ë§
results = []
for i, row in df.iterrows():
    print(f"{i+1}/{len(df)}: {row['name']}...", end=" ")
    url = row.get("profile_url", "")
    if pd.isna(url) or url.strip() == "":
        print("âŒ No profile_url")
        continue
    info = parse_scholar_profile(url)
    combined = {**row.to_dict(), **info}
    results.append(combined)
    print("âœ… Done")
    time.sleep(1.5)

# ğŸ’¾ CSVë¡œ ì €ì¥
output_df = pd.DataFrame(results)
output_df.to_csv("final_scholar_results.csv", index=False)
print("âœ… final_scholar_results.csv ì €ì¥ ì™„ë£Œ!")